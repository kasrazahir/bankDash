{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hashlib, binascii\n",
    "import numpy as np\n",
    "import time\n",
    "from shutil import copyfile\n",
    "from os import listdir\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hashit(df):\n",
    "    hashs = []\n",
    "    for index, row in df.iterrows():\n",
    "        h = hashlib.new('ripemd160')\n",
    "        it = str(row['item'])\n",
    "        it2= ' '.join(re.findall(r\"[\\w']+\", it))\n",
    "        h.update(it2.encode())\n",
    "        h.update(str(row['credit']).encode())\n",
    "        h.update(str(row['debit']).encode())\n",
    "        h.update(str(row['date']).encode())\n",
    "        hashed =h.hexdigest()\n",
    "        hashs.append(hashed)\n",
    "    return hashs\n",
    "\n",
    "def combineThem (old, new, file):\n",
    "    old['custom'].fillna(\"\",inplace=True)\n",
    "    old.fillna(value=0,inplace=True)\n",
    "    new.fillna(value=0,inplace=True)\n",
    "    assert new.dtypes['debit'] == 'float64'\n",
    "    assert new.dtypes['credit'] == 'float64'\n",
    "    assert old.dtypes['debit'] == 'float64'\n",
    "    assert old.dtypes['credit'] == 'float64'\n",
    "    new['hash']= hashit(new)\n",
    "    hashfound = []\n",
    "    for index, row in new.iterrows():\n",
    "        hashfound.append(row['hash'] in old['hash'].values)\n",
    "    new['hashfound']=hashfound\n",
    "    new.loc[new['hashfound'] == False, 'account']=file.split(\".\")[0];\n",
    "    newItems = new[new['hashfound'] == False]\n",
    "    oldToSave = old[oldColumns]\n",
    "    newToSave = newItems[['date','item','debit','credit','hash','account']]\n",
    "    combined = pd.concat([oldToSave, newToSave])\n",
    "    combined['custom'].fillna(\"\",inplace=True)\n",
    "    try:\n",
    "        head = newItems['date'].sort_values().head(1).values[0]\n",
    "        tail = newItems['date'].sort_values().tail(1).values[0]\n",
    "    except:\n",
    "        head = 0;\n",
    "        tail = 0;\n",
    "    if( head == 0 ):\n",
    "        print(f\"{file} - {len(newItems)} new items added\")\n",
    "    else:\n",
    "        print(f\"{file} - {len(newItems)} new items added, ranging from {head} to {tail}\")\n",
    "    return combined[oldColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line.csv - 0 new items added\n",
      "visa2.csv - 0 new items added\n"
     ]
    }
   ],
   "source": [
    "dlFiles = listdir(\"./download\")\n",
    "try:\n",
    "    dlFiles.remove('.DS_Store')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "miliTime = int(round(time.time() * 1000))\n",
    "oldColumns=['date','item','debit','credit','custom','hash', 'account']\n",
    "newColumns=['date','item','debit','credit','card']\n",
    "# for file in dlFiles:\n",
    "#     old = pd.read_csv(\"./assets/\"+file, header=None,names=oldColumns)\n",
    "#     new = pd.read_csv(\"./download/\"+file, header=None, names=newColumns)\n",
    "#     combined = combineThem(old, new, file)\n",
    "#     combined.to_csv(f'./assets/backup/{file.split(\".\")[0]}-{str(miliTime)}.{file.split(\".\")[1]}', index=False, header=False)\n",
    "    \n",
    "old = pd.read_csv(\"./assets/data.csv\", header=None,names=oldColumns)\n",
    "combined = old\n",
    "for file in dlFiles:\n",
    "    new = pd.read_csv(\"./download/\"+file, header=None, names=newColumns)\n",
    "    combined = combineThem(combined, new, file)\n",
    "combined.to_csv(f'./assets/backup/data-{str(miliTime)}.csv', index=False, header=False)\n",
    "combined.to_csv(f'./assets/data.csv', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hash the data file\n",
    "# old = pd.read_csv(\"./assets/data.csv\", header=None,names=oldColumns)\n",
    "# old['custom'].fillna(\"\",inplace=True)\n",
    "# old.fillna(value=0,inplace=True)\n",
    "# assert old.dtypes['debit'] == 'float64'\n",
    "# assert old.dtypes['credit'] == 'float64'\n",
    "# old['hash']= hashit(old)\n",
    "# old.to_csv(f'./assets/data.csv', index=False, header=False)\n",
    "\n",
    "# hash the other files\n",
    "# for file in dlFiles:\n",
    "#     old = pd.read_csv(\"./assets/cards/\"+file, header=None,names=oldColumns)\n",
    "#     old['custom'].fillna(\"\",inplace=True)\n",
    "#     old.fillna(value=0,inplace=True)\n",
    "#     assert old.dtypes['debit'] == 'float64'\n",
    "#     assert old.dtypes['credit'] == 'float64'\n",
    "#     old['hash']= hashit(old)\n",
    "#     old.to_csv(f'./assets/{file.split(\".\")[0]}.{file.split(\".\")[1]}', index=False, header=False)\n",
    "\n",
    "# # populate account field in data\n",
    "# oldColumns=['date','item','debit','credit','custom','hash', 'account']\n",
    "\n",
    "# data = pd.read_csv(\"./assets/data.csv\", header=None,names=oldColumns)\n",
    "# for file in dlFiles:\n",
    "#     new = pd.read_csv(\"./assets/\"+file, header=None,names=oldColumns)\n",
    "#     for index, row in new.iterrows():\n",
    "#         if(row['hash'] in data['hash'].values):\n",
    "#             data.loc[data['hash'] == row['hash'],'account']=file.split(\".\")[0]\n",
    "            \n",
    "# data.to_csv(f'./assets/data.csv', index=False, header=False) \n",
    "\n",
    "\n",
    "# # check for duplicate fields\n",
    "\n",
    "# data2 = pd.read_csv(\"./assets/data.csv\", header=None,names=oldColumns)\n",
    "# for index, row in data2.iterrows():\n",
    "#     if(data2[data2['hash']==row['hash']].count()['hash']>2):\n",
    "#         print(row['hash'], row['item'], row['debit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
